{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ticket-closure\n",
    "\n",
    "This notebook contains sample code to build a model which can predictt how long it will take to resolve tickets in an IT support system. It uses the [Incident Management dataset from the UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Incident+management+process+enriched+event+log)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling scipy-1.1.0:\n",
      "  Successfully uninstalled scipy-1.1.0\n",
      "Uninstalling numpy-1.14.3:\n",
      "  Successfully uninstalled numpy-1.14.3\n",
      "Uninstalling pandas-0.24.2:\n",
      "  Successfully uninstalled pandas-0.24.2\n",
      "\u001b[33mSkipping joblib as it is not installed.\u001b[0m\n",
      "Uninstalling scikit-learn-0.20.3:\n",
      "  Successfully uninstalled scikit-learn-0.20.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scipy==1.4.1\n",
      "  Using cached https://files.pythonhosted.org/packages/dc/29/162476fd44203116e7980cfbd9352eef9db37c49445d1fec35509022f6aa/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy==1.18.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.2MB 2.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.24.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/de/a0d3defd8f338eaf53ef716e40ef6d6c277c35d50e09b586e170169cdf0d/pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.1MB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib==0.14.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 39.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn==0.22.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.1MB 11.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting lightgbm==2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 28.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas==0.24.1) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas==0.24.1) (2.7.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas==0.24.1) (1.11.0)\n",
      "Installing collected packages: numpy, scipy, pandas, joblib, scikit-learn, lightgbm\n",
      "Successfully installed joblib-0.14.1 lightgbm-2.3.1 numpy-1.18.1 pandas-0.24.1 scikit-learn-0.22.1 scipy-1.4.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y scipy numpy pandas joblib scikit-learn\n",
    "!pip install scipy==1.4.1 numpy==1.18.1 pandas==0.24.1 joblib==0.14.1 scikit-learn==0.22.1 lightgbm==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the training data, run the provided shell script.\n",
    "\n",
    "```shell\n",
    "./scripts/get-training-data.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (19,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "# https://archive.ics.uci.edu/ml/datasets/Incident+management+process+enriched+event+log\n",
    "TRAIN_FILE = \"incident_event_log.csv\"\n",
    "\n",
    "_date_parser = lambda x: pd.NaT if x == '?' else datetime.strptime(x, \"%d/%m/%Y %H:%M\")\n",
    "train_df = pd.read_csv(\n",
    "    TRAIN_FILE,\n",
    "    parse_dates=[\n",
    "        \"opened_at\",\n",
    "        \"resolved_at\",\n",
    "        \"closed_at\",\n",
    "        \"sys_created_at\",\n",
    "        \"sys_updated_at\"\n",
    "    ],\n",
    "    infer_datetime_format=False,\n",
    "    converters={\n",
    "        \"opened_at\": _date_parser,\n",
    "        \"resolved_at\": _date_parser,\n",
    "        \"closed_at\": _date_parser,\n",
    "        \"sys_created_at\": _date_parser,\n",
    "        \"sys_updated_at\": _date_parser\n",
    "    },\n",
    "    na_values = ['?']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reassignment_count</th>\n",
       "      <th>reopen_count</th>\n",
       "      <th>sys_mod_count</th>\n",
       "      <th>opened_at</th>\n",
       "      <th>sys_created_at</th>\n",
       "      <th>sys_updated_at</th>\n",
       "      <th>contact_type</th>\n",
       "      <th>location</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>u_symptom</th>\n",
       "      <th>cmdb_ci</th>\n",
       "      <th>impact</th>\n",
       "      <th>urgency</th>\n",
       "      <th>priority</th>\n",
       "      <th>assignment_group</th>\n",
       "      <th>u_priority_confirmation</th>\n",
       "      <th>notify</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>closed_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>2016-02-29 01:23:00</td>\n",
       "      <td>2016-02-29 01:23:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Location 143</td>\n",
       "      <td>Category 55</td>\n",
       "      <td>Subcategory 170</td>\n",
       "      <td>Symptom 72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>3 - Moderate</td>\n",
       "      <td>Group 56</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>2016-02-29 01:23:00</td>\n",
       "      <td>2016-02-29 08:53:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Location 143</td>\n",
       "      <td>Category 55</td>\n",
       "      <td>Subcategory 170</td>\n",
       "      <td>Symptom 72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>3 - Moderate</td>\n",
       "      <td>Group 56</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>2016-02-29 01:23:00</td>\n",
       "      <td>2016-02-29 11:29:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Location 143</td>\n",
       "      <td>Category 55</td>\n",
       "      <td>Subcategory 170</td>\n",
       "      <td>Symptom 72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>3 - Moderate</td>\n",
       "      <td>Group 56</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>2016-02-29 01:23:00</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Location 143</td>\n",
       "      <td>Category 55</td>\n",
       "      <td>Subcategory 170</td>\n",
       "      <td>Symptom 72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>3 - Moderate</td>\n",
       "      <td>Group 56</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-29 04:40:00</td>\n",
       "      <td>2016-02-29 04:57:00</td>\n",
       "      <td>2016-02-29 04:57:00</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Location 165</td>\n",
       "      <td>Category 40</td>\n",
       "      <td>Subcategory 215</td>\n",
       "      <td>Symptom 471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>3 - Moderate</td>\n",
       "      <td>Group 70</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-06 10:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reassignment_count  reopen_count  sys_mod_count           opened_at  \\\n",
       "0                   0             0              0 2016-02-29 01:16:00   \n",
       "1                   0             0              2 2016-02-29 01:16:00   \n",
       "2                   0             0              3 2016-02-29 01:16:00   \n",
       "3                   0             0              4 2016-02-29 01:16:00   \n",
       "4                   0             0              0 2016-02-29 04:40:00   \n",
       "\n",
       "       sys_created_at      sys_updated_at contact_type      location  \\\n",
       "0 2016-02-29 01:23:00 2016-02-29 01:23:00        Phone  Location 143   \n",
       "1 2016-02-29 01:23:00 2016-02-29 08:53:00        Phone  Location 143   \n",
       "2 2016-02-29 01:23:00 2016-02-29 11:29:00        Phone  Location 143   \n",
       "3 2016-02-29 01:23:00 2016-03-05 12:00:00        Phone  Location 143   \n",
       "4 2016-02-29 04:57:00 2016-02-29 04:57:00        Phone  Location 165   \n",
       "\n",
       "      category      subcategory    u_symptom cmdb_ci      impact     urgency  \\\n",
       "0  Category 55  Subcategory 170   Symptom 72     NaN  2 - Medium  2 - Medium   \n",
       "1  Category 55  Subcategory 170   Symptom 72     NaN  2 - Medium  2 - Medium   \n",
       "2  Category 55  Subcategory 170   Symptom 72     NaN  2 - Medium  2 - Medium   \n",
       "3  Category 55  Subcategory 170   Symptom 72     NaN  2 - Medium  2 - Medium   \n",
       "4  Category 40  Subcategory 215  Symptom 471     NaN  2 - Medium  2 - Medium   \n",
       "\n",
       "       priority assignment_group  u_priority_confirmation         notify  \\\n",
       "0  3 - Moderate         Group 56                    False  Do Not Notify   \n",
       "1  3 - Moderate         Group 56                    False  Do Not Notify   \n",
       "2  3 - Moderate         Group 56                    False  Do Not Notify   \n",
       "3  3 - Moderate         Group 56                    False  Do Not Notify   \n",
       "4  3 - Moderate         Group 70                    False  Do Not Notify   \n",
       "\n",
       "  problem_id           closed_at  \n",
       "0        NaN 2016-03-05 12:00:00  \n",
       "1        NaN 2016-03-05 12:00:00  \n",
       "2        NaN 2016-03-05 12:00:00  \n",
       "3        NaN 2016-03-05 12:00:00  \n",
       "4        NaN 2016-03-06 10:00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "\n",
    "# drop columns\n",
    "#    * stuff you can only know after you've closed the ticket\n",
    "#    * 'number', which is an incident identifier that is super high-cardinality\n",
    "#    * high-cardinality columns that are basically obfuscated employee IDs (like 'created_by')\n",
    "#    * 'caller_id': not creating stateful features like \"number of previous tickets from this caller\"\n",
    "drop_cols = [\n",
    "    \"active\",\n",
    "    \"assigned_to\",\n",
    "    \"caller_id\",\n",
    "    \"caused_by\",\n",
    "    \"closed_code\",\n",
    "    \"incident_state\",\n",
    "    \"knowledge\",\n",
    "    \"made_sla\",\n",
    "    \"number\",\n",
    "    \"opened_by\",\n",
    "    \"resolved_at\",\n",
    "    \"resolved_by\",\n",
    "    \"rfc\",\n",
    "    \"sys_created_by\",\n",
    "    \"sys_updated_by\",\n",
    "    \"vendor\"\n",
    "]\n",
    "train_df = train_df[[col for col in train_df.columns if col not in drop_cols]]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target, 'time_to_close'\n",
    "TARGET_COL = 'time_to_close'\n",
    "train_df[TARGET_COL] = (train_df['closed_at'] - train_df['opened_at']) / np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticket_closure_lib.transformers import OrdinalConverter\n",
    "from ticket_closure_lib.transformers import DateColTransformer\n",
    "from ticket_closure_lib.transformers import FeatureRemover\n",
    "\n",
    "feature_map = {\n",
    "    \"impact\": {\n",
    "        \"3 - Low\": 1,\n",
    "        \"2 - Medium\": 2,\n",
    "        \"1 - High\": 3\n",
    "    },\n",
    "    \"priority\": {\n",
    "        \"4 - Low\": 1,\n",
    "        \"3 - Moderate\": 2,\n",
    "        \"2 - High\": 3,\n",
    "        \"1 - Critical\": 4\n",
    "    },\n",
    "    \"urgency\": {\n",
    "        \"3 - Low\": 1,\n",
    "        \"2 - Medium\": 2,\n",
    "        \"1 - High\": 3\n",
    "    }\n",
    "}\n",
    "ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('convert_some_to_int', OrdinalConverter(feature_map=feature_map)),\n",
    "        ('fill_na', SimpleImputer(strategy=\"constant\", fill_value=\"placeholder\")),\n",
    "        ('encode', OrdinalEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "numeric_features = [\n",
    "    col for col in dict(train_df.dtypes).keys()\n",
    "    if (\n",
    "        train_df.dtypes[col] == np.dtype('int64') or\n",
    "        train_df.dtypes[col] == np.dtype('float64')\n",
    "    )\n",
    "]\n",
    "categorical_features = [\n",
    "    col for col in dict(train_df.dtypes).keys()\n",
    "    if train_df.dtypes[col] == np.dtype('O')\n",
    "]\n",
    "\n",
    "#  https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "# create a feature engineering Python\n",
    "lgb_estimator = lgb.LGBMRegressor(\n",
    "    boosting_type='gbdt',\n",
    "    max_depth=10,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=1000,\n",
    "    num_leaves = 30,\n",
    "    objective='regression',\n",
    "    n_jobs=4,\n",
    "    silent=False\n",
    ")\n",
    "\n",
    "cols_to_drop = [\n",
    "    \"sys_created_at\",\n",
    "    \"sys_updated_at\",\n",
    "    \"opened_at\",\n",
    "    \"closed_at\"\n",
    "]\n",
    "\n",
    "ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"placeholder\")),\n",
    "        (\"encode\", OrdinalEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_cols = list(train_df.select_dtypes(\"O\").columns)\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('date_cols', DateColTransformer()),\n",
    "        ('remove_intermediate', FeatureRemover(cols_to_drop=cols_to_drop)),\n",
    "        ('convert_some_to_int', OrdinalConverter(feature_map=feature_map)),\n",
    "        ('ordinal_col_transformer', ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"ordinal\", ordinal_transformer, categorical_cols)\n",
    "            ]\n",
    "        )),\n",
    "#         ('fill_na', SimpleImputer(strategy=\"constant\", fill_value=\"placeholder\")),\n",
    "#         ('encode', OrdinalEncoder()),\n",
    "        ('regressor', lgb_estimator)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X = train_df[[col for col in train_df.columns if col is not TARGET_COL]]\n",
    "y = train_df[TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = pipeline.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median ticket duration: 9.37 days\n",
      "MAE: 9.71 days\n",
      "MSE: 2903021411202.4043\n"
     ]
    }
   ],
   "source": [
    "print(f\"median ticket duration: {round(train_df[TARGET_COL].median() / (60 * 60 * 24.0), 2)} days\")\n",
    "print(f\"MAE: {round(sklearn.metrics.mean_absolute_error(preds, y) / (60.0 * 60.0 * 24.0), 2)} days\")\n",
    "print(f\"MSE: {sklearn.metrics.mean_squared_error(preds, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "\n",
    "Now that the model is trained, save it to local storage so it can be used in an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_MODEL_FILE_NAME = \"model.pkl\"\n",
    "with open(LOCAL_MODEL_FILE_NAME, \"wb\") as f:\n",
    "    pickle.dump(mod, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Cloud Storage\n",
    "\n",
    "At this point in the notebook, we've trained a model but that model only exists on the same machine as this notebook. Let's push it to [Amazon S3](https://aws.amazon.com/s3/) so that we can pull it and re-use it later.\n",
    "\n",
    "`S3_TRAINING_ARTIFACT_BUCKET` below should be replaced with the name of the bucket you created in CloudFormation. Visit the AWS CloudFormation section of the console to find that name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "S3_TRAINING_ARTIFACT_BUCKET = \"ticket-closure-model-artifacts-358790040914-us-east-1\"\n",
    "S3 = boto3.resource('s3')\n",
    "S3.meta.client.upload_file(\n",
    "    LOCAL_MODEL_FILE_NAME,\n",
    "    S3_TRAINING_ARTIFACT_BUCKET,\n",
    "    LOCAL_MODEL_FILE_NAME\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
