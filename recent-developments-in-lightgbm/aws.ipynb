{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM + Dask\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"./_img/lightgbm.svg\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"./_img/dask-horizontal.svg\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"./_img/aws.svg\" width=\"150\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use `lightgbm.dask` to train a LightGBM model on data stored as a [Dask DataFrame](https://docs.dask.org/en/latest/dataframe.html) or [Dask Array](https://docs.dask.org/en/latest/array.html).\n",
    "\n",
    "It uses `FargateCluster` from [`dask-cloudprovider`](https://github.com/dask/dask-cloudprovider) to create a distributed cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Set up a cluster on AWS Fargate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ecr-details.json\", \"r\") as f:\n",
    "    ecr_details = json.loads(f.read())\n",
    "\n",
    "CONTAINER_IMAGE = ecr_details[\"repository\"][\"repositoryUri\"] + \":1\"\n",
    "print(f\"scheduler and worker image: {CONTAINER_IMAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, set up your AWS credentials. If you're unsure how to do this, see [the AWS docs](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"FILL ME IN\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"FILL ME IN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a cluster with 3 workers. See https://cloudprovider.dask.org/en/latest/aws.html#dask_cloudprovider.aws.FargateCluster for more options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cloudprovider.aws import FargateCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "n_workers = 3\n",
    "cluster = FargateCluster(\n",
    "    image=CONTAINER_IMAGE,\n",
    "    worker_cpu=512,\n",
    "    worker_mem=4096,\n",
    "    n_workers=n_workers,\n",
    "    fargate_use_private_ip=False,\n",
    "    scheduler_timeout=\"15 minutes\",\n",
    "    find_address_timeout=60 * 10,\n",
    ")\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"View the dashboard: {cluster.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the link above to view a diagnostic dashboard while you run the training code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask.distributed import wait\n",
    "from lightgbm.dask import DaskLGBMRegressor\n",
    "\n",
    "num_rows = 1e6\n",
    "num_features = 1e2\n",
    "num_partitions = 10\n",
    "rows_per_chunk = num_rows / num_partitions\n",
    "\n",
    "data = da.random.random((num_rows, num_features), (rows_per_chunk, num_features))\n",
    "\n",
    "labels = da.random.random((num_rows, 1), (rows_per_chunk, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the Dask Arrays `data` and `labels` are lazy. Before training, you can force the cluster to compute them by running `.persist()` and then wait for that computation to finish by `wait()`-ing on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.persist()\n",
    "labels = labels.persist()\n",
    "_ = wait(data)\n",
    "_ = wait(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data set up on the workers, train a model. `lightgbm.dask.DaskLGBMRegressor` has an interface that tries to stay as close as possible to the non-Dask scikit-learn interface to LightGBM (`lightgbm.sklearn.LGBMRegressor`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_reg = DaskLGBMRegressor(\n",
    "    silent=False,\n",
    "    max_depth=5,\n",
    "    random_state=708,\n",
    "    objective=\"regression_l2\",\n",
    "    learning_rate=0.1,\n",
    "    tree_learner=\"data\",\n",
    "    n_estimators=10,\n",
    "    min_child_samples=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "dask_reg.fit(\n",
    "    client=client,\n",
    "    X=data,\n",
    "    y=labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model produced by this training run is an instance of `DaskLGBMRegressor`. To get a regular non-Dask model (which can be pickled and saved), run `.to_local()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = dask_reg.to_local()\n",
    "type(local_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize this model by looking at a data frame representation of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model.booster_.trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
